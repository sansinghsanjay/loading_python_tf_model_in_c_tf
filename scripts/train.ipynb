{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSanjay Singh\\nsan.singhsanjay@gmail.com\\nJune-2021\\nTo train a simple CNN on MNIST dataset\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sanjay Singh\n",
    "san.singhsanjay@gmail.com\n",
    "June-2021\n",
    "To train a simple CNN on MNIST dataset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "IMG_W = 28\n",
    "IMG_H = 28\n",
    "IMG_C = 3\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 70\n",
    "CLASSES = 10\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "image_data_path = \"/notebooks/trainingSet/\"\n",
    "train_csv_path = \"/notebooks/intermediate_outputs/train_data.csv\"\n",
    "val_csv_path = \"/notebooks/intermediate_outputs/val_data.csv\"\n",
    "target_path = \"/notebooks/trained_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate data and pass in batches\n",
    "def data_generator(train_df):\n",
    "\twhile(True):\n",
    "\t\timage_batch = np.ndarray((BATCH_SIZE, IMG_W, IMG_H, IMG_C))\n",
    "\t\timage_label = np.ndarray((BATCH_SIZE, CLASSES))\n",
    "\t\tn = 0\n",
    "\t\tfor i in range(train_df.shape[0]):\n",
    "\t\t\tdir_name = str(train_df.iloc[i]['label']) + \"/\"\n",
    "\t\t\timage_batch[n] = tf.keras.preprocessing.image.load_img(image_data_path + dir_name + train_df.iloc[i]['imagename'])\n",
    "\t\t\timage_label[n] = tf.one_hot(train_df.iloc[i]['label'], CLASSES)\n",
    "\t\t\tn = n + 1\n",
    "\t\t\tif(n == BATCH_SIZE):\n",
    "\t\t\t\tn = 0\n",
    "\t\t\t\tyield image_batch, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_df:  (35000, 2)\n"
     ]
    }
   ],
   "source": [
    "# loading train_csv data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "print(\"Shape of train_df: \", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of val_df:  (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "# loading val_csv data\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "print(\"Shape of val_df: \", val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading val data\n",
    "val_images = np.ndarray((val_df.shape[0], IMG_W, IMG_H, IMG_C))\n",
    "val_labels = np.ndarray((val_df.shape[0], CLASSES))\n",
    "for i in range(val_df.shape[0]):\n",
    "\tdir_name = str(val_df.iloc[i]['label']) + \"/\"\n",
    "\tval_images[i] = tf.keras.preprocessing.image.load_img(image_data_path + dir_name + val_df.iloc[i]['imagename'])\n",
    "\tval_labels[i] = tf.one_hot(val_df.iloc[i]['label'], CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1982528   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,006,762\n",
      "Trainable params: 2,006,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# defining CNN architecture\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_W, IMG_H, IMG_C)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 148s 282ms/step - loss: 2.7918 - accuracy: 0.8198 - val_loss: 0.0972 - val_accuracy: 0.9715\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0966 - accuracy: 0.9706 - val_loss: 0.0765 - val_accuracy: 0.9795\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.1127 - val_accuracy: 0.9745\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0875 - val_accuracy: 0.9770\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.0897 - val_accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "steps = train_df.shape[0] // BATCH_SIZE\n",
    "generator = data_generator(train_df)\n",
    "history = model.fit_generator(generator, epochs=EPOCHS, steps_per_epoch=steps, validation_data=(val_images, val_labels), \n",
    "verbose=1)\n",
    "model.save(target_path + \"model_v1.h5\")\n",
    "print(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved history of model\n"
     ]
    }
   ],
   "source": [
    "file_pi = open(target_path + \"history_v1\", 'wb')\n",
    "pickle.dump(history.history, file_pi)\n",
    "file_pi.close()\n",
    "print(\"Successfully saved history of model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
